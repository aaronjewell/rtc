services:
  load-balancer:
    image: nginx:latest
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api

  api:
    build:
      context: .
      dockerfile: api/Dockerfile
    environment:
      NODE_ENV: ${NODE_ENV}
      PORT: ${PORT}
      DB_HOST: database
      DB_USER: ${DB_USER}
      DB_PASSWORD_FILE: /run/secrets/db_password
      DB_DATABASE: ${DB_DATABASE}
      JWT_SECRET_FILE: /run/secrets/jwt_secret
      JWT_EXPIRATION: ${JWT_EXPIRATION}
      SERVICE_DISCOVERY_HOST: service-discovery:2181
      TEST_USERNAME: ${TEST_USERNAME}
      TEST_PASSWORD: ${TEST_PASSWORD}
      TEST_EMAIL: ${TEST_EMAIL}
      LOGSTASH_HOST: logstash
      LOGSTASH_PORT: 5000
    secrets:
      - db_password
      - jwt_secret
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${PORT}/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      database:
        condition: service_healthy
      service-discovery:
        condition: service_started

  chat-server:
    build:
      context: .
      dockerfile: chat-server/Dockerfile
    environment:
      KV_STORE_HOST: kv-store
      KV_KEYSPACE: chat_service
      NODE_ENV: ${NODE_ENV}
      PORT: 80
      JWT_SECRET_FILE: /run/secrets/jwt_secret
      KAFKA_BROKER: kafka:9092
      REDIS_HOST: redis
      REDIS_PORT: 6379
      SERVICE_DISCOVERY_HOST: service-discovery:2181
      SERVER_ID: "chat"
      LOGSTASH_HOST: logstash
      LOGSTASH_PORT: 5000
    deploy:
      mode: replicated
      replicas: 2
    secrets:
      - jwt_secret
    depends_on:
      chat-server-migrate:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      kv-store:
        condition: service_healthy
      redis:
        condition: service_healthy
      service-discovery:
        condition: service_started

  chat-server-migrate:
    build:
      context: ./chat-server
      dockerfile: Dockerfile.migrate
    environment:
      KV_STORE_HOST: kv-store
      KV_KEYSPACE: chat_service
    depends_on:
      kv-store:
        condition: service_healthy
    restart: "no"  # Run once and exit

  presence-server:
    build:
      context: .
      dockerfile: presence-server/Dockerfile
    environment:
      NODE_ENV: ${NODE_ENV}
      PORT: 80
      JWT_SECRET_FILE: /run/secrets/jwt_secret
      KV_STORE_HOST: kv-store
      SERVICE_DISCOVERY_HOST: service-discovery:2181
      SERVER_ID: "presence"
      LOGSTASH_HOST: logstash
      LOGSTASH_PORT: 5000
    deploy:
      mode: replicated
      replicas: 2
    secrets:
      - jwt_secret
    depends_on:
      kv-store:
        condition: service_healthy
      service-discovery:
        condition: service_started
      kafka:
        condition: service_healthy

  database:
    image: mysql:8.3
    env_file:
      - .env
    environment:
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
      MYSQL_USER: ${DB_USER}
      MYSQL_DATABASE: ${DB_DATABASE}
      MYSQL_PASSWORD_FILE: /run/secrets/db_password
    ports:
      - "3306:3306"
    secrets:
       - db_root_password
       - db_password
    healthcheck:
      test: ["CMD-SHELL", "exit | mysql -h localhost -P 3306 -u $$MYSQL_USER -p$$(cat $$MYSQL_ROOT_PASSWORD_FILE)" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    volumes:
      - mysql-data:/var/lib/mysql

  kv-store:
    image: cassandra:latest
    ports:
      - "9042:9042"
    volumes:
      - cassandra-data:/var/lib/cassandra
    environment:
      - CASSANDRA_CLUSTER_NAME=chat_cluster
      - CASSANDRA_ENDPOINT_SNITCH=SimpleSnitch
    healthcheck:
      test: ["CMD", "cqlsh", "-e", "SELECT now() FROM system.local;"]
      interval: 15s
      timeout: 5s
      retries: 10

  service-discovery:
    image: zookeeper:3.8
    environment:
      - ZOO_MY_ID=1
      - ZOO_SERVERS=server.1=zookeeper:2888:3888;2181
    volumes:
      - zookeeper-data:/data
      - zookeeper-datalog:/datalog

  zookeeper-kafka:
    image: bitnami/zookeeper:latest
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
    volumes:
      - zookeeper-kafka-data:/bitnami
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: bitnami/kafka:latest
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-kafka:2181
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      ALLOW_PLAINTEXT_LISTENER: yes
    ports:
      - "9092:9092"
    volumes:
      - kafka-data:/bitnami
    depends_on:
      zookeeper-kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  kafka-setup:
    image: confluentinc/cp-kafka:latest
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      bash -c '
        echo "Waiting for Kafka to be ready..." &&
        /usr/bin/kafka-topics --create --if-not-exists \
          --bootstrap-server kafka:9092 \
          --topic chat-messages \
          --partitions 12 \
          --replication-factor 1 \
          --config cleanup.policy=delete \
          --config retention.ms=3600000 \
          --config retention.bytes=524288000 \
          --config delete.retention.ms=60000 \
          --config min.compaction.lag.ms=0 \
          --config segment.ms=300000 \
          --config message.timestamp.type=CreateTime'

  message-dispatcher:
    build:
      context: .
      dockerfile: message-dispatcher/Dockerfile
    environment:
      NODE_ENV: ${NODE_ENV}
      PORT: 8080
      KAFKA_BROKER: kafka:9092
      REDIS_HOST: redis
      SERVICE_DISCOVERY_HOST: service-discovery:2181
      SERVER_ID: "message-dispatcher"
      LOGSTASH_HOST: logstash
      LOGSTASH_PORT: 5000
    deploy:
      mode: replicated
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    healthcheck:
      test: ["CMD-SHELL", "curl -f \"http://localhost:$$PORT/health\" | grep -q '\"status\":\"ok\"' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    depends_on:
      kafka-setup:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      service-discovery:
        condition: service_started

  redis:
    image: redis:6
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 10s
      timeout: 5s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:8.12.0
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    depends_on:
      elasticsearch:
        condition: service_healthy

  kibana:
    image: docker.elastic.co/kibana/kibana:8.12.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=["http://elasticsearch:9200"]
      - XPACK_SECURITY_ENABLED=false
    depends_on:
      elasticsearch:
        condition: service_healthy

secrets:
  db_root_password:
    file: ./secrets/db_root_password.txt
  db_password:
    file: ./secrets/db_password.txt
  jwt_secret:
    file: ./secrets/jwt_secret.txt

volumes:
  cassandra-data:
  mysql-data:
  zookeeper-data:
  zookeeper-datalog:
  zookeeper-kafka-data:
  kafka-data:
  redis-data:
  elasticsearch-data:
